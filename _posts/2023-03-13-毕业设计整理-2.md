---
layout: post
read_time: true
show_date: true
title:  毕业设计整理-2
date:   2021-01-25 13:32:20 -0600
description: cpp模板常见混淆点做一个自我区分
img: posts/20220214/corgi.jpg
tags: [c++, Parallel, Concurrent]
author: DD
github:  https://github.com/WhatNameCouldIRegister/Fast-Neural-Style-Transfer.git
mathjax: yes
---
**鉴于视频处理脚本开发已经基本完成**
**本文专注于style-transfer网络训练部分**

## 基本概念

以下内容转载自 https://blog.csdn.net/m0_54028213/article/details/127125842

- 输入中有一张内容图片（Content Image）和一张样式视频（Style Video）
- 模型所要训练的不是卷积神经网络的权重，而是合成图片，它是样式迁移过程中唯一需要更新的变量，即样式迁移所需迭代的参数模型
深度神经网络凭借多个层逐级抽取图像的特征，因此可以选择其中某些层的输出作为内容特征或者样式特征（上图中的卷积神经网络第二层输出内容特征，第一层和第三层输出样式特征）

#### 选择其中某些层的输出作为内容特征或者样式特征（上图中的卷积神经网络第二层输出内容特征，第一层和第三层输出样式特征）
- 对于一张输入图片来讲，每一层的卷积神经网络都会有一个输出（特征），整个基于 CNN 的样式迁移的目的是训练出一张合成图片，使得合成图片和内容图片放进同样一个卷积神经网络的时候，合成图片在某一层的输出能够匹配上内容图片在某一层的损失（内容损失，Content Loss），即它们在内容上是相近的；同理，合成图片和内容图片所使用的是同一个卷积神经网络，在某些层的输出（特征）在样式上能够匹配的上。如果训练出一张合成图片同时满足以上需求的话，就可以认为它既保留了内容图片的内容，又保留了样式图片的样式
一般来说，越靠近输入层，越容易抽取图片的细节信息；反之，越容易抽取图片的全局信息
- 为了避免合成图片过多地保留内容图片的细节，选择靠近输出的层（即内容层）来输出图片的内容特征
- 选择不同层的输出（即风格层）来匹配局部和全局的样式
在使用卷积神经网络抽取特征时，只需要用到从输入层到最靠近输出层的内容层或者样式层之间的所有层
- 因为在训练的时候无需改变预训练的卷积神经网络的模型参数，所以可以在训练开始之前就提取出内容特征和风格特征

#### 通过前向传播（实线箭头方向）计算样式迁移的损失函数，并通过反向传播（虚线箭头方向）迭代模型参数，即不断更新合成图片

#### 关键点总结

1、样式迁移常用的损失函数由 3 部分组成：内容损失、样式损失和全变分损失

内容损失使合成图片与内容图片在内容特征上接近
样式损失使合成图片与样式图片在样式特征上接近
全变分损失有助于减少合成图片中的噪点
2、可以通过预训练好的卷积神经网络来抽取图像的特征，并通过最小化损失函数来不断更新合成图片来作为模型参数

3、使用格拉姆矩阵表达样式层输出的样式

## 关于数据集

MSCOCO数据集是微软开发维护的大型图像数据集，数据集标注类型对应任务包括物体检测、关键点检测、实例分割、 stuff分割 （没有特定形状的物体） ，全景分割人体关键点， 人体密度检测 等等。